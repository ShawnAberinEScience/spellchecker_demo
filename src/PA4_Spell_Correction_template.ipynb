{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i3m9JjeM5U5"
      },
      "source": [
        "# **Programming Assessment \\#4**\n",
        "\n",
        "Names: \\<please supply your names\\>\n",
        "\n",
        "More information on the assessment is found in our Canvas course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxtmCAZwNoeU"
      },
      "source": [
        "# **Load Data**\n",
        "\n",
        "*While you don't have to separate your code into blocks, it might be easier if you separated loading your data from actually implementation of your code. Consider placing all loading of data into the code block below.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: editdistpy in c:\\python39\\lib\\site-packages (0.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# The code is defining a function called `make_p` that takes a DataFrame `df` as input.\n",
        "# lang must contain a column 'count' that contains number types\n",
        "#load error data\n",
        "import pandas as pd\n",
        "%pip install editdistpy\n",
        "from editdistpy import damerau_osa as ld\n",
        "def make_p(df):\n",
        "    total = df['count'].sum()\n",
        "    inv = 1/total\n",
        "    df['P'] = df['count']*inv\n",
        "    print (df['P'])\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "x=''\n",
        "with open(\"count_1edit.txt\", \"r\") as f:\n",
        "    x = f.read().splitlines()\n",
        "gen = (dat.split('\\t') for dat in x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       0.023469\n",
            "1       0.021908\n",
            "2       0.019732\n",
            "3       0.019169\n",
            "4       0.014307\n",
            "          ...   \n",
            "1582    0.000026\n",
            "1583    0.000026\n",
            "1584    0.000026\n",
            "1585    0.000026\n",
            "1586    0.000026\n",
            "Name: P, Length: 1587, dtype: float64\n",
            "       count         P\n",
            "error                 \n",
            "e|i      917  0.023469\n",
            "a|e      856  0.021908\n",
            "i|e      771  0.019732\n",
            "e|a      749  0.019169\n",
            "a|i      559  0.014307\n",
            "...      ...       ...\n",
            " |c        1  0.000026\n",
            " |a        1  0.000026\n",
            " |'        1  0.000026\n",
            " w|        1  0.000026\n",
            " t|t       1  0.000026\n",
            "\n",
            "[1587 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "data = [(rec[0],int(rec[1]))for rec in gen]\n",
        "err = pd.DataFrame.from_records(data, columns=['error', 'count'])\n",
        "err = make_p(err)\n",
        "err = err.set_index(['error'])\n",
        "print(err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "CbvxU2oTM4IV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading gutenburg: Package 'gutenburg' not found in\n",
            "[nltk_data]     index\n"
          ]
        },
        {
          "cell_type": "code",
          "execution_count": 72,
          "metadata": {
            "id": "CbvxU2oTM4IV"
          },
          "outputs": [
            {
              "name": "stderr",
              "output_type": "stream",
              "text": [
                "[nltk_data] Downloading package gutenberg to\n",
                "[nltk_data]     C:\\Users\\matth\\AppData\\Roaming\\nltk_data...\n",
                "[nltk_data]   Package gutenberg is already up-to-date!\n"
              ]
            },
            {
              "data": {
                "text/plain": [
                  "True"
                ]
              },
              "execution_count": 33,
              "metadata": {},
              "output_type": "execute_result"
            }
          ],
          "source": [
            "#loading corpus files\n",
            "import nltk\n",
            "nltk.download('gutenberg')\n",
            "# nltk.corpus.gutenberg.fileids()"
          ]
        },
        {
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loading corpus files\n",
        "import nltk\n",
        "nltk.download('gutenburg')\n",
        "# nltk.corpus.gutenberg.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting all documents from NLTK's Project Gutenberg Collection...\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "# TODO: consolidate into a Finder class\n",
        "from string import punctuation as punc, digits as dig\n",
        "print(\"Extracting all documents from NLTK's Project Gutenberg Collection...\")\n",
        "all_words = Counter()\n",
        "\n",
        "for filename in nltk.corpus.gutenberg.fileids():\n",
        "  words = [word.lower() for word in nltk.corpus.gutenberg.words(filename) if word not in punc and word not in dig]\n",
        "  all_words.update(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          index     0\n",
            "0          emma   866\n",
            "1            by  8512\n",
            "2          jane   303\n",
            "3        austen     3\n",
            "4          1816     1\n",
            "...         ...   ...\n",
            "42287  endowing     1\n",
            "42288   delving     1\n",
            "42289  germinal     1\n",
            "42290   blither     1\n",
            "42291  ushering     1\n",
            "\n",
            "[42292 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "lang = pd.DataFrame.from_dict(all_words, orient='index').reset_index()\n",
        "print(lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "lang = lang.rename(columns={'index':'word', 0:'count'})\n",
        "lang = lang.set_index(['word'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word\n",
            "emma        3.939490e-04\n",
            "by          3.872164e-03\n",
            "jane        1.378367e-04\n",
            "austen      1.364719e-06\n",
            "1816        4.549065e-07\n",
            "                ...     \n",
            "endowing    4.549065e-07\n",
            "delving     4.549065e-07\n",
            "germinal    4.549065e-07\n",
            "blither     4.549065e-07\n",
            "ushering    4.549065e-07\n",
            "Name: P, Length: 42292, dtype: float64\n",
            "          count             P\n",
            "word                         \n",
            "emma        866  3.939490e-04\n",
            "by         8512  3.872164e-03\n",
            "jane        303  1.378367e-04\n",
            "austen        3  1.364719e-06\n",
            "1816          1  4.549065e-07\n",
            "...         ...           ...\n",
            "endowing      1  4.549065e-07\n",
            "delving       1  4.549065e-07\n",
            "germinal      1  4.549065e-07\n",
            "blither       1  4.549065e-07\n",
            "ushering      1  4.549065e-07\n",
            "\n",
            "[42292 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "lang = make_p(lang)\n",
        "print(lang)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8YCZLi-N0uR"
      },
      "source": [
        "# **Noisy Channel Model Implementation**\n",
        "\n",
        "*Again, you don't have to follow this directly, but consider placing your implementation of the model in the code block below.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "VqKjpUrkOSnC"
      },
      "outputs": [],
      "source": [
        "def candidates(input, all_words):\n",
        "      # 1 edit distance away from word\n",
        "      if input in all_words: return [input]\n",
        "      # candidates = [w for w in all_words if get_d(input,w) <3 ]\n",
        "\n",
        "      candidates = None\n",
        "      d = 1\n",
        "      MAX = 90 #magic number set to the longest possible edit distance ig?\n",
        "      while not candidates and d <= MAX:\n",
        "            candidates = [w for w in all_words if ld.distance(input,w,d) > -1]\n",
        "            d+=1\n",
        "\n",
        "      return candidates\n",
        "def spell_correct(candidate_list,tok):\n",
        "    if tok in candidate_list: return tok\n",
        "    n=10\n",
        "    probable = lang.loc[candidate_list].sort_values(['P'], ascending=False).head(n)\n",
        "    print(lang.loc[candidate_list])\n",
        "      # maxI = 0\n",
        "      # for i in range(len(candidate_list)):\n",
        "      #       x = P(candidate_list[i], all_words)\n",
        "      #       if x > maxX:\n",
        "      #             maxX = x\n",
        "      #             maxI = i\n",
        "      # TODO: Add the error model. Kyle, can you please make an algo that finds the first error and query the probability?\n",
        "    return probable.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_err(input_word, candidate_word):\n",
        "    print(candidate_word)\n",
        "    if len(input_word) == len(candidate_word) and input_word != candidate_word:\n",
        "        for i in range(len(input_word) - 1):\n",
        "            if input_word[i] == candidate_word[i + 1] and input_word[i + 1] == candidate_word[i]:\n",
        "                edit_type = \"trans\"\n",
        "                edit =\"|\".join(( candidate_word[i:i+2]  ,input_word[i:i+2]))\n",
        "                print(edit_type)\n",
        "                return edit_type, edit\n",
        "            if input_word[i] != candidate_word[i]:\n",
        "                edit_type = \"sub\"\n",
        "                edit =\"|\".join(( candidate_word[i]  ,input_word[i]))\n",
        "                print(edit_type)\n",
        "                return edit_type, edit\n",
        "\n",
        "    \n",
        "            \n",
        "\n",
        "    elif len(input_word) < len(candidate_word):\n",
        "        # Check for insertion\n",
        "        edit_type = \"ins\"\n",
        "        edit = \"\"\n",
        "        i, j = 0, 0\n",
        "        while i < len(input_word) and j < len(candidate_word):\n",
        "            if input_word[i] != candidate_word[j]:\n",
        "                edit += input_word[j-1] + \"|\" + input_word[j-1] + candidate_word[j]\n",
        "                print(edit_type)\n",
        "                return edit_type, edit\n",
        "        \n",
        "            i += 1\n",
        "            j += 1\n",
        "\n",
        "\n",
        "    elif len(input_word) > len(candidate_word):\n",
        "        # Check for deletion\n",
        "        edit_type = \"del\"\n",
        "        edit = \"\"\n",
        "        i, j = 0, 0\n",
        "        while i < len(input_word) and j < len(candidate_word):\n",
        "            if input_word[i] != candidate_word[j]:\n",
        "                edit += input_word[i-1] + input_word[i] + \"|\" + candidate_word[i - 1]\n",
        "                print(edit_type)\n",
        "                return edit_type, edit\n",
        "       \n",
        "            i += 1\n",
        "            j += 1\n",
        "        if i == len(input_word):\n",
        "            return edit_type, edit\n",
        "\n",
        "    # Check for transposition\n",
        "    \n",
        "    print('roke')\n",
        "    return None, None  # No valid edit type found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            " mohter\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mother\n",
            "trans\n",
            "morter\n",
            "sub\n",
            "     Word candidate edit_type   edit      P(c)    P(w|c)  P(c) x P(w|c)\n",
            "0  mohter    mother     trans  th|ht  0.000552  0.000819   4.519144e-07\n",
            "1  mohter    morter       sub    r|h  0.000005  0.000102   5.122690e-10\n"
          ]
        }
      ],
      "source": [
        "#main function\n",
        "test_input = input()\n",
        "c = candidates(test_input, all_words)\n",
        "if test_input in c:\n",
        "    print(\"Word is spelled correctly\")\n",
        "else:\n",
        "    df = pd.DataFrame(columns=['Word', 'candidate', 'edit_type', 'edit', 'P(c)', 'P(w|c)', 'P(c) x P(w|c)'])\n",
        "    #show all candidates\n",
        "    i = 0\n",
        "    for candidate in c:\n",
        "        #get probability of word\n",
        "        wordP = lang.at[ candidate,'P']\n",
        "\n",
        "        edit_type, edit = get_err(test_input, candidate)\n",
        "        #get probability of error\n",
        "        try:\n",
        "            editP = err.at[edit,'P']\n",
        "         \n",
        "        except:\n",
        "            editP = 0\n",
        "        temp = pd.DataFrame({'Word' : test_input, 'candidate' : candidate, 'edit_type' : edit_type, 'edit' : edit, 'P(c)' : wordP, 'P(w|c)' : editP, 'P(c) x P(w|c)' : (wordP * editP)}\n",
        "                            , index=[i])\n",
        "        df = pd.concat([df, temp])\n",
        "        i += 1\n",
        "    print(df)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "nbformat": 4,
    "nbformat_minor": 0
  }
}