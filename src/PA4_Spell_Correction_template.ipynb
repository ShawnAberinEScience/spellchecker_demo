{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3m9JjeM5U5"
   },
   "source": [
    "# **Programming Assessment \\#4**\n",
    "\n",
    "Names: \\<please supply your names\\>\n",
    "\n",
    "More information on the assessment is found in our Canvas course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxtmCAZwNoeU"
   },
   "source": [
    "# **Load Data**\n",
    "\n",
    "*While you don't have to separate your code into blocks, it might be easier if you separated loading your data from actually implementation of your code. Consider placing all loading of data into the code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is defining a function called `make_p` that takes a DataFrame `df` as input.\n",
    "# lang must contain a column 'count' that contains number types\n",
    "#load error data\n",
    "import pandas as pd\n",
    "%pip install editdistpy\n",
    "from editdistpy import damerau_osa as ld\n",
    "def make_p(df):\n",
    "    total = df['count'].sum()\n",
    "    inv = 1/total\n",
    "    df['P'] = df['count']*inv\n",
    "    print (df['P'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=''\n",
    "with open(\"count_1edit.txt\", \"r\") as f:\n",
    "    x = f.read().splitlines()\n",
    "gen = (dat.split('\\t') for dat in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.023469\n",
      "1       0.021908\n",
      "2       0.019732\n",
      "3       0.019169\n",
      "4       0.014307\n",
      "          ...   \n",
      "1582    0.000026\n",
      "1583    0.000026\n",
      "1584    0.000026\n",
      "1585    0.000026\n",
      "1586    0.000026\n",
      "Name: P, Length: 1587, dtype: float64\n",
      "       count         P\n",
      "error                 \n",
      "e|i      917  0.023469\n",
      "a|e      856  0.021908\n",
      "i|e      771  0.019732\n",
      "e|a      749  0.019169\n",
      "a|i      559  0.014307\n",
      "...      ...       ...\n",
      " |c        1  0.000026\n",
      " |a        1  0.000026\n",
      " |'        1  0.000026\n",
      " w|        1  0.000026\n",
      " t|t       1  0.000026\n",
      "\n",
      "[1587 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = [(rec[0],int(rec[1]))for rec in gen]\n",
    "err = pd.DataFrame.from_records(data, columns=['error', 'count'])\n",
    "err = make_p(err)\n",
    "err = err.set_index(['error'])\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CbvxU2oTM4IV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading gutenburg: Package 'gutenburg' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading corpus files\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "nltk.download('gutenburg')\n",
    "# nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all documents from NLTK's Project Gutenberg Collection...\n",
      "          index     0\n",
      "0          emma   866\n",
      "1            by  8512\n",
      "2          jane   303\n",
      "3        austen     3\n",
      "4          1816     1\n",
      "...         ...   ...\n",
      "42307  endowing     1\n",
      "42308   delving     1\n",
      "42309  germinal     1\n",
      "42310   blither     1\n",
      "42311  ushering     1\n",
      "\n",
      "[42312 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# TODO: consolidate into a Finder class\n",
    "import string\n",
    "print(\"Extracting all documents from NLTK's Project Gutenberg Collection...\")\n",
    "all_words = Counter()\n",
    "for filename in nltk.corpus.gutenberg.fileids():\n",
    "  words = [word.lower() for word in nltk.corpus.gutenberg.words(filename) if word not in string.punctuation]\n",
    "  all_words.update(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index     0\n",
      "0          emma   866\n",
      "1            by  8512\n",
      "2          jane   303\n",
      "3        austen     3\n",
      "4          1816     1\n",
      "...         ...   ...\n",
      "42307  endowing     1\n",
      "42308   delving     1\n",
      "42309  germinal     1\n",
      "42310   blither     1\n",
      "42311  ushering     1\n",
      "\n",
      "[42312 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "lang = pd.DataFrame.from_dict(all_words, orient='index').reset_index()\n",
    "print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count\n",
      "word           \n",
      "emma        866\n",
      "by         8512\n",
      "jane        303\n",
      "austen        3\n",
      "1816          1\n",
      "...         ...\n",
      "endowing      1\n",
      "delving       1\n",
      "germinal      1\n",
      "blither       1\n",
      "ushering      1\n",
      "\n",
      "[42312 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "lang = lang.rename(columns={'index':'word', 0:'count'})\n",
    "lang = lang.set_index(['word'])\n",
    "print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "emma        3.892499e-04\n",
      "by          3.825976e-03\n",
      "jane        1.361925e-04\n",
      "austen      1.348441e-06\n",
      "1816        4.494802e-07\n",
      "                ...     \n",
      "endowing    4.494802e-07\n",
      "delving     4.494802e-07\n",
      "germinal    4.494802e-07\n",
      "blither     4.494802e-07\n",
      "ushering    4.494802e-07\n",
      "Name: P, Length: 42312, dtype: float64\n",
      "          count             P\n",
      "word                         \n",
      "emma        866  3.892499e-04\n",
      "by         8512  3.825976e-03\n",
      "jane        303  1.361925e-04\n",
      "austen        3  1.348441e-06\n",
      "1816          1  4.494802e-07\n",
      "...         ...           ...\n",
      "endowing      1  4.494802e-07\n",
      "delving       1  4.494802e-07\n",
      "germinal      1  4.494802e-07\n",
      "blither       1  4.494802e-07\n",
      "ushering      1  4.494802e-07\n",
      "\n",
      "[42312 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "lang = make_p(lang)\n",
    "print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8YCZLi-N0uR"
   },
   "source": [
    "# **Noisy Channel Model Implementation**\n",
    "\n",
    "*Again, you don't have to follow this directly, but consider placing your implementation of the model in the code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def get_d(str_1, str_2):\n",
    "#     rows = len(str_1) + 1\n",
    "#     cols = len(str_2) + 1\n",
    "#     dMatrix = np.zeros((rows, cols), dtype=int)\n",
    "#     dMatrix[0]= [*range(0, cols)]\n",
    "#     for i in range(1, rows):\n",
    "#         dMatrix[i][0] = i\n",
    "            \n",
    "        \n",
    "#     for col in range(1, cols):\n",
    "#         for row in range(1, rows):\n",
    "#             cost = 0\n",
    "#             if str_1[row - 1] == str_2[col - 1]:\n",
    "#                cost = -1\n",
    "#             dMatrix[row][col] = min(dMatrix[row - 1][col], dMatrix[row][col - 1], dMatrix[row-1][col-1] + cost)+1\n",
    "#             if row > 1 and col > 1:\n",
    "#                 dMatrix[row][col] = min (dMatrix[row-2][col-2],dMatrix[row][col])\n",
    "    \n",
    "#     return dMatrix[row][col]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "VqKjpUrkOSnC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: editdistpy in c:\\python39\\lib\\site-packages (0.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_err(str_1, str_2):\n",
    "    rows = len(str_1) + 1\n",
    "    cols = len(str_2) + 1\n",
    "    dMatrix = np.zeros((rows, cols), dtype=int)\n",
    "    dMatrix[0]= [*range(0, cols)]\n",
    "    for i in range(1, rows):\n",
    "        dMatrix[i][0] = i\n",
    "            \n",
    "        \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if str_1[row - 1] == str_2[col - 1]:\n",
    "               cost = 0\n",
    "            else:\n",
    "               cost = 1\n",
    "            if str_1[row - 1] == str_2[col] and str_1[row] == str_2[col-1]:\n",
    "                # transpose\n",
    "                pass\n",
    "            dMatrix[row][col] = min(dMatrix[row - 1][col] + 1, dMatrix[row][col - 1] + 1, dMatrix[row-1][col-1] + cost)\n",
    "            if row > 1 and col > 1:\n",
    "                dMatrix[row][col] = min (dMatrix[row-2][col-2],dMatrix[row][col])\n",
    "    \n",
    "    return dMatrix[row][col]\n",
    "\n",
    "\n",
    "def candidates(input, all_words):\n",
    "      # 1 edit distance away from word\n",
    "      if input in all_words: return [input]\n",
    "      # candidates = [w for w in all_words if get_d(input,w) <3 ]\n",
    "\n",
    "      candidates = None\n",
    "      d = 1\n",
    "      MAX = 90 #magic number set to the longest possible edit distance ig?\n",
    "      while not candidates and d <= MAX:\n",
    "            candidates = [w for w in all_words if ld.distance(input,w,d) > -1]\n",
    "            d+=1\n",
    "\n",
    "      return candidates\n",
    "def spell_correct(candidate_list,tok):\n",
    "    if tok in candidate_list: return tok\n",
    "    n=10\n",
    "    probable = lang.loc[candidate_list].sort_values(['P'], ascending=False).head(n)\n",
    "    print(lang.loc[candidate_list])\n",
    "      # maxI = 0\n",
    "      # for i in range(len(candidate_list)):\n",
    "      #       x = P(candidate_list[i], all_words)\n",
    "      #       if x > maxX:\n",
    "      #             maxX = x\n",
    "      #             maxI = i\n",
    "      # TODO: Add the error model. Kyle, can you please make an algo that finds the first error and query the probability?\n",
    "    return probable.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kyle's error trace\n",
    "# def calculate_edit_type_and_edit(input_word, candidate_word):\n",
    "#     if len(input_word) == len(candidate_word):\n",
    "#         # Check for substitution\n",
    "#         diff_count = 0\n",
    "#         edit_type = \"sub\"\n",
    "#         edit = \"\"\n",
    "#         for i in range(len(input_word)):\n",
    "#             if input_word[i] != candidate_word[i]:\n",
    "#                 diff_count += 1\n",
    "#                 edit += candidate_word[i]\n",
    "#         if diff_count == 1:\n",
    "#             return edit_type, edit\n",
    "\n",
    "#     elif len(input_word) + 1 == len(candidate_word):\n",
    "#         # Check for insertion\n",
    "#         edit_type = \"ins\"\n",
    "#         edit = \"\"\n",
    "#         i, j = 0, 0\n",
    "#         while i < len(input_word) and j < len(candidate_word):\n",
    "#             if input_word[i] != candidate_word[j]:\n",
    "#                 edit += candidate_word[j]\n",
    "#                 j += 1\n",
    "#             else:\n",
    "#                 i += 1\n",
    "#                 j += 1\n",
    "#         if j == len(candidate_word):\n",
    "#             return edit_type, edit\n",
    "\n",
    "#     elif len(input_word) - 1 == len(candidate_word):\n",
    "#         # Check for deletion\n",
    "#         edit_type = \"del\"\n",
    "#         edit = \"\"\n",
    "#         i, j = 0, 0\n",
    "#         while i < len(input_word) and j < len(candidate_word):\n",
    "#             if input_word[i] != candidate_word[j]:\n",
    "#                 edit += input_word[i]\n",
    "#                 i += 1\n",
    "#             else:\n",
    "#                 i += 1\n",
    "#                 j += 1\n",
    "#         if i == len(input_word):\n",
    "#             return edit_type, edit\n",
    "\n",
    "#     # Check for transposition\n",
    "#     if len(input_word) == len(candidate_word) and input_word != candidate_word:\n",
    "#         for i in range(len(input_word) - 1):\n",
    "#             if input_word[i] == candidate_word[i + 1] and input_word[i + 1] == candidate_word[i]:\n",
    "#                 edit_type = \"trans\"\n",
    "#                 edit = input_word[i:i+2]\n",
    "#                 return edit_type, edit\n",
    "\n",
    "#     return None, None  # No valid edit type found\n",
    "\n",
    "# # Get user input\n",
    "# #user_input = input(\"Enter a word for spell correction: \")\n",
    "\n",
    "# corpus = \"This is a sample text for the spell correction model. Modeler is working fine.\"\n",
    "# model = Modeler(corpus)\n",
    "\n",
    "# print(model.model)\n",
    "\n",
    "# finder = Finder(model.model)\n",
    "\n",
    "# token = \"food\"\n",
    "# candidates = finder.getCandidates(token)\n",
    "\n",
    "# print(candidates)\n",
    "\n",
    "# results = []\n",
    "# valid_edit_types = [\"ins\", \"trans\", \"sub\" ,\"del\", ]\n",
    "# for candidate in candidates:\n",
    "#     candidate_word, probability = candidate[0], candidate[1]\n",
    "#     edit_type, edit = calculate_edit_type_and_edit(token, candidate_word)\n",
    "#     print(\"\\n\")\n",
    "#     print(edit_type,edit)\n",
    "#     print(\"\\n\")\n",
    "#     if edit_type in valid_edit_types:\n",
    "#         result = {\n",
    "#             \"word\": token,\n",
    "#             \"candidate\": candidate_word,\n",
    "#             \"edit_type\": edit_type,\n",
    "#             \"edit\": edit,\n",
    "#             \"P(c)\": probability,\n",
    "#             \"P(w|c)\": model.model[candidate_word],\n",
    "#             \"P(c) x P(w|c)\": probability * model.model[candidate_word]\n",
    "#         }\n",
    "#         results.append(result)\n",
    "#     else:\n",
    "#         result = \"broken\"\n",
    "#         results.append(result)\n",
    "\n",
    "# df = pd.DataFrame(results)\n",
    "\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count         P\n",
      "word                     \n",
      "they      13104  0.005890\n",
      "theory       25  0.000011\n",
      "thereby      47  0.000021\n",
      "thebez        3  0.000001\n",
      "theology      5  0.000002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>13104</td>\n",
       "      <td>0.005890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thereby</th>\n",
       "      <td>47</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theory</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theology</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thebez</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count         P\n",
       "word                     \n",
       "they      13104  0.005890\n",
       "thereby      47  0.000021\n",
       "theory       25  0.000011\n",
       "theology      5  0.000002\n",
       "thebez        3  0.000001"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#main function\n",
    "test_input = \"thexxxxyyz\"\n",
    "c = candidates(test_input, all_words)\n",
    "spell_correct(c,test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f4b3deeac0a5ce6c43bde11bfee6a0d7b0549337061a7646d07811ade3818cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
