{"cells":[{"cell_type":"markdown","metadata":{"id":"3i3m9JjeM5U5"},"source":["# **Programming Assessment \\#4**\n","\n","Names: \\<please supply your names\\>\n","\n","More information on the assessment is found in our Canvas course."]},{"cell_type":"markdown","metadata":{"id":"HxtmCAZwNoeU"},"source":["# **Load Data**\n","\n","*While you don't have to separate your code into blocks, it might be easier if you separated loading your data from actually implementation of your code. Consider placing all loading of data into the code block below.*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CbvxU2oTM4IV"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5332,"status":"ok","timestamp":1699153388563,"user":{"displayName":"Kyle Francis Lim","userId":"02927512807106829255"},"user_tz":-480},"id":"5LKyvcN_burY","outputId":"42c4eae8-3e97-4c42-ca03-97ab42c8c505"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: editdistpy in c:\\python39\\lib\\site-packages (0.1.3)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n","\n","[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install editdistpy"]},{"cell_type":"markdown","metadata":{"id":"r8YCZLi-N0uR"},"source":["# **Noisy Channel Model Implementation**\n","\n","*Again, you don't have to follow this directly, but consider placing your implementation of the model in the code block below.*"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":375,"status":"ok","timestamp":1699154306025,"user":{"displayName":"Kyle Francis Lim","userId":"02927512807106829255"},"user_tz":-480},"id":"VqKjpUrkOSnC","outputId":"facdc7ce-dcbf-4ec6-e486-58e5f57968fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'This': 0.07142857142857142, 'is': 0.14285714285714285, 'a': 0.07142857142857142, 'sample': 0.07142857142857142, 'text': 0.07142857142857142, 'for': 0.07142857142857142, 'the': 0.07142857142857142, 'spell': 0.07142857142857142, 'correction': 0.07142857142857142, 'model.': 0.07142857142857142, 'Modeler': 0.07142857142857142, 'working': 0.07142857142857142, 'fine.': 0.07142857142857142}\n","[('for', 0.07142857142857142)]\n","        0\n","0  broken\n"]}],"source":["from collections import Counter\n","import pandas as pd\n","import numpy as np\n","\n","from editdistpy import damerau_osa\n","\n","# Finder\n","class Finder:\n","    def __init__(self, model):\n","        self.model = model\n","\n","    def queryModel(self, tok):\n","        exists = tok in self.model\n","        val = self.model[tok] if exists else None\n","        return exists, val\n","\n","    def getD(self, tok):\n","        candidates = []\n","        max_d = 1\n","        sentinel = 45 << 1\n","        while not (candidates or max_d > sentinel):\n","            candidates = [word for word in self.model.keys() if damerau_osa.distance(tok, word, max_d) > -1]\n","            max_d += 1\n","        return candidates\n","\n","    def getCandidates(self, tok, n=5):\n","        exists, _ = self.queryModel(tok)\n","        candidates = []\n","        if exists:\n","            return [tok]\n","        else:\n","            candidates = self.getD(tok)\n","            p_c = [self.model[word] for word in candidates]\n","            weighted = list(zip(candidates, p_c))\n","            weighted.sort(key=lambda tu: tu[1], reverse=True)\n","            islong = len(weighted) >= n\n","            return weighted[::n] if islong else weighted\n","\n","# Modeler\n","class Modeler:\n","    def __init__(self, corpus):\n","        if isinstance(corpus, str):\n","\n","            words = corpus.split()\n","            counts = Counter(words)\n","            self.model = self.getP_C(counts)\n","        elif isinstance(corpus, Counter):\n","            self.model = self.getP_C(corpus)\n","\n","    def getP_C(self, counts):\n","        total = sum(counts.values())\n","        r_t = 1 / total\n","        keys = counts.keys()\n","        vals = np.array(list(counts.values())) * r_t\n","        return dict(zip(keys, vals))\n","\n","\n","\n","def calculate_edit_type_and_edit(input_word, candidate_word):\n","    if len(input_word) == len(candidate_word):\n","        # substitution\n","        diff_count = 0\n","        edit_type = \"sub\"\n","        edit = \"\"\n","        for i in range(len(input_word)):\n","            if input_word[i] != candidate_word[i]:\n","                diff_count += 1\n","                edit += candidate_word[i]\n","        if diff_count == 1:\n","            return edit_type, edit\n","\n","    elif len(input_word) + 1 == len(candidate_word):\n","        # insertion\n","        edit_type = \"ins\"\n","        edit = \"\"\n","        i, j = 0, 0\n","        while i < len(input_word) and j < len(candidate_word):\n","            if input_word[i] != candidate_word[j]:\n","                edit += candidate_word[j]\n","                j += 1\n","            else:\n","                i += 1\n","                j += 1\n","        if j == len(candidate_word) - 1:\n","            return edit_type, edit\n","\n","    elif len(input_word) - 1 == len(candidate_word):\n","        # deletion\n","        edit_type = \"del\"\n","        edit = \"\"\n","        i, j = 0, 0\n","        while i < len(input_word) and j < len(candidate_word):\n","            if input_word[i] != candidate_word[j]:\n","                edit += input_word[i]\n","                i += 1\n","            else:\n","                i += 1\n","                j += 1\n","        if i == len(input_word) - 1:\n","            return edit_type, edit\n","\n","    # transposition\n","    if len(input_word) == len(candidate_word) and input_word != candidate_word:\n","        for i in range(len(input_word) - 1):\n","            if input_word[i] == candidate_word[i + 1] and input_word[i + 1] == candidate_word[i]:\n","                edit_type = \"trans\"\n","                edit = input_word[i:i+2]\n","                return edit_type, edit\n","\n","    return None, None\n","\n","# someone load the \n","corpus = \"This is a sample text for the spell correction model. Modeler is working fine.\"\n","model = Modeler(corpus)\n","print(model.model)\n","\n","finder = Finder(model.model)\n","\n","token = \"afar\"\n","candidates = finder.getCandidates(token)\n","\n","print(candidates)\n","results = []\n","# fun_ny = lambda cand:calculate_edit_type_and_edit(token,cand)\n","# genny = map(fun_ny,candidates)\n","for candidate, probability in candidates:\n","    edit_type, edit = calculate_edit_type_and_edit(token, candidate)\n","    if edit_type:\n","        result = {\n","            \"word\": token,\n","            \"candidate\": candidate,\n","            \"edit_type\": edit_type,\n","            \"edit\": edit,\n","            \"P(c)\": probability,\n","            \"P(w|c)\": model.model[candidate],\n","            \"P(c) x P(w|c)\": probability * model.model[candidate]\n","        }\n","    else:\n","        result = \"broken\"\n","        results.append(result)\n","\n","df = pd.DataFrame(results)\n","\n","print(df)\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"}},"nbformat":4,"nbformat_minor":0}
